{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a similarity index for LLMs\n",
    "\n",
    "Sometimes, it feels like a prompt in two different LLMs leads to the very same output. I tried to measure how true it was.\n",
    "\n",
    "## Data collection\n",
    "\n",
    "I ran the same prompt in three different LLMs: gemini-2.5-flash-lite, gpt-5-nano and grok-4-fast-non-reasoning.\n",
    "\n",
    "The system prompt was:\n",
    "\n",
    "> You are an expert at world History. You know that History is as much what happened as what is said to have happened. You are not ensconsed in any particular vision of History, especially not one from school or from university. You know that no version of History is right or false, but that History is a narrative that people use to explain the present. You know that History is always situated and created in and by a given context, but you are expert enough that you can move between contexts and present History from different points of views.\n",
    "\n",
    "The prompt itself was:\n",
    "\n",
    "> Provide a list of 200 dates that are most relevant to world History. I do not mean relevant to a world History class at school or in college, but relevant to world History in general.\n",
    "\n",
    "> The result should be a Python list of the form [{\"event\": description of the event, \"year\": year of the event, \"date\": date of the event in the format 1970-12-01}]\n",
    "\n",
    "I should have 100 batches of 200 events from each LLM.\n",
    "\n",
    "(In truth, out of roughly 300 prompts, only once did an LLM provide 200 events).\n",
    "\n",
    "## Data cleaning\n",
    "\n",
    "I removed all content that was not a Python List.\n",
    "\n",
    "Gemini returned many dates set to \"1970-12-01\". I reconciled the results by selecting all events where the year in the \"year\" field differed from the year in the \"date\" field. I then looked for events with the exact same name, or with a Levenshtein distance of less than 15, from the data output by OpenAI and xAI, and copied their date value.\n",
    "\n",
    "## Data analysis\n",
    "\n",
    "I now harmonize the data to have the same number of batches of the same size from all 3 LLMs.\n",
    "\n",
    "I will compare each batch to all other batches from the same provider, and then from all other batches from the other 2 providers, using the [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index).\n",
    "\n",
    "I use the 'date' field as the point of comparison between batches, as the 'event' field might vary considerably (from a lexicometric perspective) although it is the same (from the perspective of human understanding).\n",
    "\n",
    "The value of the Jaccard index is bound to be an underestimate, as many events were given different dates by the LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"clean_data/merged_events_corrected_fuzzy.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['batch'] = df['source'] + '_' + df['batch'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drops all rows after Dec 31, 2022, to remove absurd events from xAI and future events from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"year\"].notna() & (df[\"year\"] != \"\")]\n",
    "df = df[df[\"year\"].astype(int) < 2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removes rows where the date and year are mismatched (Gemini had lots of these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_from_date(date_str):\n",
    "    \"\"\"Extract year from date string before '-\\d\\d-\\d\\d' pattern\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    match = re.search(r'^(.+?)-\\d\\d-\\d\\d', str(date_str))\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['date'].apply(extract_year_from_date) == df['year'].astype(str)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop batches with less than a given number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('batch').filter(lambda x: len(x) >= batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly truncate all other batches to the same number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_batches = df.groupby('source')['batch'].nunique().min()\n",
    "df = df.groupby('source', group_keys=False).apply(lambda x: x[x['batch'].isin(x['batch'].unique()[:min_batches])])\n",
    "df = df.groupby('batch', group_keys=False).apply(lambda x: x.sample(n=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of batches for each source\n",
    "int(len(df.groupby(['source', 'batch']).size().reset_index(name='count')) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>batch</th>\n",
       "      <th>event</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63652</th>\n",
       "      <td>gemini</td>\n",
       "      <td>gemini_1</td>\n",
       "      <td>Rise of social media</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63519</th>\n",
       "      <td>gemini</td>\n",
       "      <td>gemini_1</td>\n",
       "      <td>Wright Brothers' first successful flight</td>\n",
       "      <td>1903</td>\n",
       "      <td>1903-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63478</th>\n",
       "      <td>gemini</td>\n",
       "      <td>gemini_1</td>\n",
       "      <td>Black Death pandemic begins</td>\n",
       "      <td>1347</td>\n",
       "      <td>1347-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63499</th>\n",
       "      <td>gemini</td>\n",
       "      <td>gemini_1</td>\n",
       "      <td>Enlightenment reaches its peak</td>\n",
       "      <td>1750</td>\n",
       "      <td>1750-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63603</th>\n",
       "      <td>gemini</td>\n",
       "      <td>gemini_1</td>\n",
       "      <td>Battle of Waterloo</td>\n",
       "      <td>1815</td>\n",
       "      <td>1815-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>xai</td>\n",
       "      <td>xai_95</td>\n",
       "      <td>Detroit bankruptcy</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>xai</td>\n",
       "      <td>xai_95</td>\n",
       "      <td>Midterms 2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>xai</td>\n",
       "      <td>xai_95</td>\n",
       "      <td>Manchester Arena bombing</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>xai</td>\n",
       "      <td>xai_95</td>\n",
       "      <td>FTX collapse</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-11-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>xai</td>\n",
       "      <td>xai_95</td>\n",
       "      <td>Hungarian Revolution</td>\n",
       "      <td>1956</td>\n",
       "      <td>1956-10-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16740 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source     batch                                     event  year  \\\n",
       "63652  gemini  gemini_1                      Rise of social media  2004   \n",
       "63519  gemini  gemini_1  Wright Brothers' first successful flight  1903   \n",
       "63478  gemini  gemini_1               Black Death pandemic begins  1347   \n",
       "63499  gemini  gemini_1            Enlightenment reaches its peak  1750   \n",
       "63603  gemini  gemini_1                        Battle of Waterloo  1815   \n",
       "...       ...       ...                                       ...   ...   \n",
       "1992      xai    xai_95                        Detroit bankruptcy  2013   \n",
       "2123      xai    xai_95                             Midterms 2022  2022   \n",
       "2067      xai    xai_95                  Manchester Arena bombing  2017   \n",
       "2128      xai    xai_95                              FTX collapse  2022   \n",
       "1619      xai    xai_95                      Hungarian Revolution  1956   \n",
       "\n",
       "             date  \n",
       "63652  2004-01-01  \n",
       "63519  1903-12-17  \n",
       "63478  1347-01-01  \n",
       "63499  1750-01-01  \n",
       "63603  1815-06-18  \n",
       "...           ...  \n",
       "1992   2013-07-18  \n",
       "2123   2022-11-08  \n",
       "2067   2017-05-22  \n",
       "2128   2022-11-11  \n",
       "1619   1956-10-23  \n",
       "\n",
       "[16740 rows x 5 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Jaccard Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        avg_jaccard_openai  avg_jaccard_xai  avg_jaccard_gemini\n",
      "source                                                         \n",
      "gemini            0.138185         0.103441            0.242873\n",
      "openai            0.179187         0.066326            0.138185\n",
      "xai               0.066326         0.184209            0.103441\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def jaccard_index(set1, set2):\n",
    "    \"\"\"Compute Jaccard index between two sets\"\"\"\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "# Create a dictionary of date sets for each batch\n",
    "batch_dates = df.groupby('batch')['date'].apply(set).to_dict()\n",
    "batch_source = df.groupby('batch')['source'].first().to_dict()\n",
    "\n",
    "results = []\n",
    "\n",
    "for batch in batch_dates.keys():\n",
    "    source = batch_source[batch]\n",
    "    dates = batch_dates[batch]\n",
    "    \n",
    "    openai_scores = []\n",
    "    xai_scores = []\n",
    "    gemini_scores = []\n",
    "    \n",
    "    for other_batch in batch_dates.keys():\n",
    "        if batch == other_batch:\n",
    "            continue\n",
    "        \n",
    "        other_source = batch_source[other_batch]\n",
    "        other_dates = batch_dates[other_batch]\n",
    "        \n",
    "        jaccard = jaccard_index(dates, other_dates)\n",
    "        \n",
    "        if other_source == 'openai':\n",
    "            openai_scores.append(jaccard)\n",
    "        elif other_source == 'xai':\n",
    "            xai_scores.append(jaccard)\n",
    "        elif other_source == 'gemini':\n",
    "            gemini_scores.append(jaccard)\n",
    "    \n",
    "    results.append({\n",
    "        'batch': batch,\n",
    "        'source': source,\n",
    "        'avg_jaccard_openai': sum(openai_scores) / len(openai_scores) if openai_scores else 0,\n",
    "        'avg_jaccard_xai': sum(xai_scores) / len(xai_scores) if xai_scores else 0,\n",
    "        'avg_jaccard_gemini': sum(gemini_scores) / len(gemini_scores) if gemini_scores else 0\n",
    "    })\n",
    "\n",
    "jaccard_df = pd.DataFrame(results)\n",
    "\n",
    "# Group by source and compute averages\n",
    "grouped_results = jaccard_df.groupby('source')[['avg_jaccard_openai', 'avg_jaccard_xai', 'avg_jaccard_gemini']].mean()\n",
    "print(grouped_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As expected, the average Jaccard index is much higher between sets of the same LLM. But in some cases, the difference is slight."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
